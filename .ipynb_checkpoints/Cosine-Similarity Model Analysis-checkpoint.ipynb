{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of Cosine-Similarity Classifier\n",
    "\n",
    "In this notebook, a version of K-Nearest Neighbors is proposed that results in a slightly higher accuracy than standard K-Nearest Neighbor models, along with a 2 times (or greater) classification speedup.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "#### Standard K-Nearest Neighbors\n",
    "K-Nearest Neighbor (K-NN) algorithms are simple supervised classification algorithms that have the capability of making robust classification on complex datasets.  K-NN is simple, so it is easy to implement.  It is a lazy learner, so it requires no training and can thus get right to classification, making it a much faster algorithm than other classification models such as SVM, regression, multi-layer perceptron, etc..  K-NN is also non-parametric, so it makes to assumptions about the data.  Because the algorithm requires no training, data can be added or taken away seamlessly, without making any major adjustments.\n",
    "\n",
    "Given a point $p$ to classify, a K-NN model will \"compare\" the passed point with all the points $x_i$ the model has available to it using some distance metric (most commonly Euclidean distance).  This process will generate the unordered set $D$ that holds the distances between $p$ and every other point in the dataset, $x_i$, in the form of $d_i$.  Next, the algorithm pulls the $k$ lowest distances (or greatest similarities) from $D$, and uses either a classic or weighted voting technique, to classify $p$ as being a member of some class $C$.  \n",
    "\n",
    "#### The Cosine-Similarity Classifier\n",
    "The Cosine-Similarity Classifier works in the same general way as most K-NN classifiers.  The primary difference with the Cosine-Similarity Classifier is in its name: it uses cosine-similarity as a distance metric instead of standard Euclidean or Manhatten distance.  Cosine-similarity is given by\n",
    "\n",
    "$$\n",
    "similarity=cos(\\theta) = \\frac{\\vec{a} \\cdot \\vec{b}}{||\\vec{a}|| ||\\vec{b}||}\n",
    "$$\n",
    "\n",
    "where $\\vec{a}$ and $\\vec{b}$ are vectors whos similarity is returned.  \n",
    "\n",
    "After testing the Cosine-Similarity Classifier on the MNIST data set, it is found that the classifier is both faster and just as, if not more accurate than go-to K-NN models from the Scikit-Learn library.  In the analysis below, I will build out the Cosine-Similarity Classifier, and run it on the MNIST data set.  I will then test a go-to K-NN model from Scikit-Learn on the MNIST dataset, finally comparing both the accuracy and classification time of the two models in a variety of situations.  All tests were run on a Intel Core 3570K CPU (no GPU here unfortunately).\n",
    "\n",
    "## Analysis\n",
    "\n",
    "Start with required imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import heapq\n",
    "from collections import Counter\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import datasets, model_selection\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "\n",
    "mnist = datasets.fetch_mldata('MNIST original')\n",
    "data, target = mnist.data, mnist.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look over the MNIST data, and make different datasets out of it for testing the classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((70000, 784), (70000,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 784), (60000,), (10000, 784), (10000,))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make an array of indices to use, in random order, the same length of the MNIST dataset\n",
    "indx = np.random.choice(len(target), 70000, replace=False)\n",
    "\n",
    "# use the random array indx to build testing data sets\n",
    "####################################################\n",
    "\n",
    "# Data set #1\n",
    "\n",
    "# stored_data/stored_target: largest size of all test datasets, with 60,000 stored examples\n",
    "# for model to use for classification\n",
    "train_img1 = [data[i] for i in indx[:60000]]\n",
    "train_img1 = np.array(train_img1)\n",
    "train_target1 = [target[i] for i in indx[:60000]]\n",
    "train_target1 = np.array(train_target1)\n",
    "\n",
    "# will be keeping test set the same for different stored data sets\n",
    "# test_data/test_target: the smaller dataset used to test model accuracy for the data sets\n",
    "test_img = [data[i] for i in indx[60000:70000]]\n",
    "test_img = np.array(test_img)\n",
    "test_target = [target[i] for i in indx[60000:70000]]\n",
    "test_target = np.array(test_target)\n",
    "\n",
    "train_img1.shape, train_target1.shape, test_img.shape, test_target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single random test image, this is just used for testing the speed at which each model can \n",
    "# classify a single point\n",
    "t_img1 = test_img[563]\n",
    "t_img1 = np.array([t_img1])\n",
    "t_target1 = test_target[563]\n",
    "t_target1 = np.array([t_target1])\n",
    "t_target1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 784), (50000,))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data set #2\n",
    "\n",
    "# stored_data/stored_target: data used by model for classificaiton of size 50,000\n",
    "train_img2 = [data[i] for i in indx[:50000]]\n",
    "train_img2 = np.array(train_img2)\n",
    "train_target2 = [target[i] for i in indx[:50000]]\n",
    "train_target2 = np.array(train_target2)\n",
    "\n",
    "train_img2.shape, train_target2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((40000, 784), (40000,))"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data set #3\n",
    "\n",
    "# stored_data/stored_target: data used by model for classificaiton of size 40,000\n",
    "train_img3 = [data[i] for i in indx[:40000]]\n",
    "train_img3 = np.array(train_img3)\n",
    "train_target3 = [target[i] for i in indx[:40000]]\n",
    "train_target3 = np.array(train_target3)\n",
    "\n",
    "train_img3.shape, train_target3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30000, 784), (30000,))"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data set #4\n",
    "\n",
    "# stored_data/stored_target: data used by model for classificaiton of size 30,000\n",
    "train_img4 = [data[i] for i in indx[:30000]]\n",
    "train_img4 = np.array(train_img4)\n",
    "train_target4 = [target[i] for i in indx[:30000]]\n",
    "train_target4 = np.array(train_target4)\n",
    "\n",
    "train_img4.shape, train_target4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 784), (20000,))"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data set #5\n",
    "\n",
    "# stored_data/stored_target: data used by model for classificaiton of size 20,000\n",
    "train_img5 = [data[i] for i in indx[:20000]]\n",
    "train_img5 = np.array(train_img5)\n",
    "train_target5 = [target[i] for i in indx[:20000]]\n",
    "train_target5 = np.array(train_target5)\n",
    "\n",
    "train_img5.shape, train_target5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 784), (10000,))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data set #6\n",
    "\n",
    "# stored_data/stored_target: data used by model for classificaiton of size 10,000\n",
    "train_img6 = [data[i] for i in indx[:10000]]\n",
    "train_img6 = np.array(train_img6)\n",
    "train_target6 = [target[i] for i in indx[:10000]]\n",
    "train_target6 = np.array(train_target6)\n",
    "\n",
    "train_img6.shape, train_target6.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 784), (1000,))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data set #7\n",
    "\n",
    "# stored_data/stored_target: data used by model for classificaiton of size 1,000\n",
    "train_img7 = [data[i] for i in indx[:1000]]\n",
    "train_img7 = np.array(train_img7)\n",
    "train_target7 = [target[i] for i in indx[:1000]]\n",
    "train_target7 = np.array(train_target7)\n",
    "\n",
    "train_img7.shape, train_target7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great.  Now we have 7 data sets to test on the classifier, ranging from just size 1,000 to size 60,000.  We also have a testing data set of size 10,000 to calculate accuracy and speed of the classifiers, as well as a smaller testing dataset of just size 1 used to pass sinlge point classification speed.\n",
    "\n",
    "Now we build the Cosine-Similarity Classifier.  The method only takes the `test_target` argument to calculate prediction accuracy, it is not actually needed for classification.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_knn(k, test_data, test_target, stored_data, stored_target):\n",
    "    \"\"\"k: number of top most similar values to vote on\n",
    "    test_data: a set of unobserved images to classify\n",
    "    test_target: the labels for the test_data (for calculating accuracy)\n",
    "    stored_data: the images already observed and available to the model\n",
    "    stored_target: labels for stored_data\n",
    "    \"\"\"\n",
    "    \n",
    "    # find similarity for every point in test_data between every other point in stored_data\n",
    "    cosim = cosine_similarity(test_data, stored_data)\n",
    "    \n",
    "    # get indices of images in stored_data that are most similar to any given test_data point\n",
    "    top = [(heapq.nlargest((k+1), range(len(i)), i.take)) for i in cosim]\n",
    "    # convert indices to numbers\n",
    "    top = [[stored_target[j] for j in i[:k]] for i in top]\n",
    "    \n",
    "    # vote, and return prediction for every image in test_data\n",
    "    pred = [max(set(i), key=i.count) for i in top]\n",
    "    pred = np.array(pred)\n",
    "    \n",
    "    # print table giving classifier accuracy using test_target\n",
    "    print(classification_report(test_target, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets look at what the Scikit-Learn K-NN method looks like.  I will put the entire Scikit-Learn K-NN classifier into a function so it can be called and tested with greater ease.\n",
    "\n",
    "All we really have to worry about with the Scikit-Learn K-NN algorithm is the value for the`n_neighbors` argument (number of neighbors to use for classification), the `weights` argument for `KNeighborsClassifier()`, which we will just leave at its default value of `uniform`, as that is the same method used in the Cosine-Similarity Classifier.  Finally, we have the `algorithm` argument for `KNeighborsClassifier()`, which we will also leave at its default value of `auto`, as it will find the optimal algorithm to use for the given data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skl_knn(k, test_data, test_target, stored_data, stored_target):\n",
    "    \"\"\"k: number of neighbors to use in classication\n",
    "    test_data: the data/targets used to test the classifier\n",
    "    stored_data: the data/targets used to classify the test_data\n",
    "    \"\"\"\n",
    "    \n",
    "    classifier = KNeighborsClassifier(n_neighbors=k)  \n",
    "    classifier.fit(stored_data, stored_target)\n",
    "\n",
    "    y_pred = classifier.predict(test_data) \n",
    "\n",
    "    print(classification_report(test_target, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is all there is to it.  Now we test how each model does on different data sets.\n",
    "\n",
    "Below, we will test the Scikit-Learn and Cosine-Similarity K-NN classifiers on each of the seven data sets, using the standard test data, as well as the single valued test data at the end to test speed of single point classification for each model.  \n",
    "\n",
    "For each data set/model pair, we will be measuring classification accuracy and speed of test_data classification.  For the Scikit-Learn model, a $k$ value of 5 will be used, and for the Cosine-Similarity model a $k$ value of 3 will be used, as those were the values found to be optimal (it is possible other values for $k$ are indeed better than the ones chosen, these values were chosen after running many tests, but will likely not be absolutely optimal).  Here goes..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      1.00      0.99       941\n",
      "        1.0       0.98      1.00      0.99      1137\n",
      "        2.0       0.99      0.97      0.98      1006\n",
      "        3.0       0.98      0.97      0.98      1040\n",
      "        4.0       0.98      0.97      0.98       931\n",
      "        5.0       0.98      0.97      0.97       911\n",
      "        6.0       0.98      0.99      0.99       994\n",
      "        7.0       0.97      0.97      0.97      1036\n",
      "        8.0       0.97      0.96      0.96       966\n",
      "        9.0       0.95      0.97      0.96      1038\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "CPU times: user 5min 45s, sys: 1.16 s, total: 5min 46s\n",
      "Wall time: 5min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img1, train_target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.99       941\n",
      "        1.0       0.96      0.99      0.98      1137\n",
      "        2.0       0.98      0.97      0.97      1006\n",
      "        3.0       0.97      0.97      0.97      1040\n",
      "        4.0       0.97      0.97      0.97       931\n",
      "        5.0       0.96      0.97      0.97       911\n",
      "        6.0       0.98      0.99      0.99       994\n",
      "        7.0       0.96      0.97      0.97      1036\n",
      "        8.0       0.99      0.93      0.96       966\n",
      "        9.0       0.96      0.96      0.96      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "CPU times: user 9min 5s, sys: 280 ms, total: 9min 5s\n",
      "Wall time: 9min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img1, train_target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99       941\n",
      "        1.0       0.97      1.00      0.98      1137\n",
      "        2.0       0.99      0.98      0.98      1006\n",
      "        3.0       0.99      0.97      0.98      1040\n",
      "        4.0       0.98      0.97      0.98       931\n",
      "        5.0       0.98      0.96      0.97       911\n",
      "        6.0       0.98      0.99      0.99       994\n",
      "        7.0       0.97      0.97      0.97      1036\n",
      "        8.0       0.96      0.95      0.96       966\n",
      "        9.0       0.95      0.97      0.96      1038\n",
      "\n",
      "avg / total       0.98      0.98      0.98     10000\n",
      "\n",
      "CPU times: user 4min 52s, sys: 1.03 s, total: 4min 53s\n",
      "Wall time: 4min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img2, train_target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.98      0.99      0.98       941\n",
      "        1.0       0.96      0.99      0.98      1137\n",
      "        2.0       0.98      0.97      0.97      1006\n",
      "        3.0       0.97      0.97      0.97      1040\n",
      "        4.0       0.98      0.97      0.97       931\n",
      "        5.0       0.96      0.97      0.97       911\n",
      "        6.0       0.98      0.99      0.98       994\n",
      "        7.0       0.96      0.97      0.97      1036\n",
      "        8.0       0.99      0.92      0.96       966\n",
      "        9.0       0.96      0.96      0.96      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "CPU times: user 8min 1s, sys: 264 ms, total: 8min 2s\n",
      "Wall time: 8min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img2, train_target2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.99       941\n",
      "        1.0       0.97      0.99      0.98      1137\n",
      "        2.0       0.98      0.97      0.98      1006\n",
      "        3.0       0.99      0.96      0.97      1040\n",
      "        4.0       0.98      0.97      0.98       931\n",
      "        5.0       0.98      0.97      0.97       911\n",
      "        6.0       0.99      0.99      0.99       994\n",
      "        7.0       0.97      0.97      0.97      1036\n",
      "        8.0       0.96      0.96      0.96       966\n",
      "        9.0       0.95      0.97      0.96      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "CPU times: user 3min 52s, sys: 864 ms, total: 3min 53s\n",
      "Wall time: 3min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img3, train_target3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98       941\n",
      "        1.0       0.95      0.99      0.97      1137\n",
      "        2.0       0.98      0.96      0.97      1006\n",
      "        3.0       0.97      0.97      0.97      1040\n",
      "        4.0       0.97      0.96      0.97       931\n",
      "        5.0       0.95      0.97      0.96       911\n",
      "        6.0       0.98      0.99      0.98       994\n",
      "        7.0       0.96      0.97      0.96      1036\n",
      "        8.0       0.99      0.92      0.95       966\n",
      "        9.0       0.95      0.95      0.95      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "CPU times: user 6min 52s, sys: 384 ms, total: 6min 52s\n",
      "Wall time: 6min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img3, train_target3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      1.00      0.98       941\n",
      "        1.0       0.97      0.99      0.98      1137\n",
      "        2.0       0.98      0.97      0.98      1006\n",
      "        3.0       0.98      0.96      0.97      1040\n",
      "        4.0       0.98      0.96      0.97       931\n",
      "        5.0       0.98      0.96      0.97       911\n",
      "        6.0       0.99      0.99      0.99       994\n",
      "        7.0       0.97      0.96      0.97      1036\n",
      "        8.0       0.96      0.96      0.96       966\n",
      "        9.0       0.94      0.96      0.95      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "CPU times: user 2min 55s, sys: 592 ms, total: 2min 55s\n",
      "Wall time: 2min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img4, train_target4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98       941\n",
      "        1.0       0.95      0.99      0.97      1137\n",
      "        2.0       0.98      0.96      0.97      1006\n",
      "        3.0       0.96      0.96      0.96      1040\n",
      "        4.0       0.97      0.95      0.96       931\n",
      "        5.0       0.96      0.96      0.96       911\n",
      "        6.0       0.98      0.99      0.98       994\n",
      "        7.0       0.96      0.97      0.96      1036\n",
      "        8.0       0.99      0.91      0.95       966\n",
      "        9.0       0.94      0.95      0.95      1038\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10000\n",
      "\n",
      "CPU times: user 4min 31s, sys: 60.1 ms, total: 4min 32s\n",
      "Wall time: 4min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img4, train_target4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      1.00      0.98       941\n",
      "        1.0       0.97      0.99      0.98      1137\n",
      "        2.0       0.98      0.97      0.97      1006\n",
      "        3.0       0.98      0.95      0.96      1040\n",
      "        4.0       0.98      0.95      0.97       931\n",
      "        5.0       0.98      0.95      0.97       911\n",
      "        6.0       0.98      0.98      0.98       994\n",
      "        7.0       0.97      0.95      0.96      1036\n",
      "        8.0       0.96      0.96      0.96       966\n",
      "        9.0       0.92      0.96      0.94      1038\n",
      "\n",
      "avg / total       0.97      0.97      0.97     10000\n",
      "\n",
      "CPU times: user 1min 59s, sys: 687 ms, total: 2min\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img5, train_target5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98       941\n",
      "        1.0       0.93      0.99      0.96      1137\n",
      "        2.0       0.98      0.95      0.96      1006\n",
      "        3.0       0.96      0.96      0.96      1040\n",
      "        4.0       0.96      0.94      0.95       931\n",
      "        5.0       0.95      0.96      0.95       911\n",
      "        6.0       0.98      0.98      0.98       994\n",
      "        7.0       0.94      0.96      0.95      1036\n",
      "        8.0       0.98      0.90      0.94       966\n",
      "        9.0       0.93      0.95      0.94      1038\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10000\n",
      "\n",
      "CPU times: user 3min 39s, sys: 440 ms, total: 3min 39s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img5, train_target5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.95      1.00      0.97       941\n",
      "        1.0       0.96      0.99      0.97      1137\n",
      "        2.0       0.98      0.96      0.97      1006\n",
      "        3.0       0.97      0.94      0.95      1040\n",
      "        4.0       0.97      0.92      0.95       931\n",
      "        5.0       0.97      0.93      0.95       911\n",
      "        6.0       0.98      0.98      0.98       994\n",
      "        7.0       0.96      0.94      0.95      1036\n",
      "        8.0       0.94      0.94      0.94       966\n",
      "        9.0       0.89      0.95      0.92      1038\n",
      "\n",
      "avg / total       0.96      0.96      0.96     10000\n",
      "\n",
      "CPU times: user 1min, sys: 308 ms, total: 1min\n",
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img6, train_target6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.97      0.99      0.98       941\n",
      "        1.0       0.91      0.99      0.95      1137\n",
      "        2.0       0.97      0.93      0.95      1006\n",
      "        3.0       0.95      0.95      0.95      1040\n",
      "        4.0       0.96      0.93      0.94       931\n",
      "        5.0       0.94      0.95      0.94       911\n",
      "        6.0       0.97      0.98      0.97       994\n",
      "        7.0       0.94      0.95      0.94      1036\n",
      "        8.0       0.98      0.86      0.92       966\n",
      "        9.0       0.91      0.93      0.92      1038\n",
      "\n",
      "avg / total       0.95      0.95      0.95     10000\n",
      "\n",
      "CPU times: user 1min 49s, sys: 348 ms, total: 1min 49s\n",
      "Wall time: 1min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img6, train_target6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.85      0.99      0.91       941\n",
      "        1.0       0.90      0.99      0.94      1137\n",
      "        2.0       0.97      0.88      0.92      1006\n",
      "        3.0       0.93      0.86      0.89      1040\n",
      "        4.0       0.95      0.80      0.87       931\n",
      "        5.0       0.93      0.84      0.88       911\n",
      "        6.0       0.96      0.94      0.95       994\n",
      "        7.0       0.95      0.85      0.90      1036\n",
      "        8.0       0.83      0.88      0.85       966\n",
      "        9.0       0.76      0.91      0.83      1038\n",
      "\n",
      "avg / total       0.90      0.89      0.90     10000\n",
      "\n",
      "CPU times: user 6.87 s, sys: 104 ms, total: 6.97 s\n",
      "Wall time: 6.09 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, test_img, test_target, train_img7, train_target7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.92      0.96      0.94       941\n",
      "        1.0       0.75      0.99      0.86      1137\n",
      "        2.0       0.95      0.82      0.88      1006\n",
      "        3.0       0.89      0.84      0.87      1040\n",
      "        4.0       0.87      0.86      0.87       931\n",
      "        5.0       0.85      0.88      0.87       911\n",
      "        6.0       0.94      0.95      0.95       994\n",
      "        7.0       0.87      0.85      0.86      1036\n",
      "        8.0       0.96      0.71      0.82       966\n",
      "        9.0       0.81      0.84      0.82      1038\n",
      "\n",
      "avg / total       0.88      0.87      0.87     10000\n",
      "\n",
      "CPU times: user 11.6 s, sys: 8.05 ms, total: 11.6 s\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, test_img, test_target, train_img7, train_target7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on even less data as sklearn model seems to drop off.\n",
    "\n",
    "The test results show the following:\n",
    "* The Cosine-Similarity Classifier either matched the Scikit-Learn K-NN accuracy wise, or beats it by 1%-2%.  \n",
    "* As far as speed of classification goes, the Cosine-Similarity Classifier tends to be between 1.5-2 times faster than the Scikit-Learn K-NN.\n",
    "* Strangely, the Cosine-Similarity Classifier tends to underperform when classifying the digit 9.  This could be on account of the fact that 4 and 9 are so similar, and thus tend to muddle the similarity metric for classification.\n",
    "\n",
    "Now we test classification speed of the two models on the single valued test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00         1\n",
      "\n",
      "CPU times: user 573 ms, sys: 244 ms, total: 817 ms\n",
      "Wall time: 590 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cos_knn(3, t_img1, t_target1, train_img1, train_target1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       1.00      1.00      1.00         1\n",
      "\n",
      "avg / total       1.00      1.00      1.00         1\n",
      "\n",
      "CPU times: user 25.9 s, sys: 144 ms, total: 26 s\n",
      "Wall time: 26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "skl_knn(5, t_img1, t_target1, train_img1, train_target1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown by the test results, the Cosine-Similarity Classifier is significantly faster at classifying single points than its corresponding Scikit-Learn classifier for larger stored data sets.\n",
    "\n",
    "\n",
    "## Room For Improvement\n",
    "Below are some points that can be used in the improvement of the Cosine-Similarity Model.\n",
    "* Tree for faster classification\n",
    "\n",
    "\n",
    "## Lessons Learned & Moving Forward\n",
    "Below is a list of main takeaways from the project, and possible future applications of the model.\n",
    "* Sometimes the best models to use are the simplest.  \n",
    "* Cosine similarity is a great similarity metric, accurate and efficient..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
